{"cells":[{"cell_type":"markdown","metadata":{"id":"nC-CXM9eADTU"},"source":["# Next Word Prediction Using GRU\n","\n","### Project Overview:\n","\n","This project aims to develop a deep learning model for predicting the next word in a given sequence of words. The model is built using Gated Recurrent Unit (GRU) networks, which are well-suited for sequence prediction tasks.\n","\n","The project includes the following steps:\n","\n","1- Data Collection: We use the text of Shakespeare's \"Hamlet\" as our dataset. This rich, complex text provides a good challenge for our model.\n","\n","2- Data Preprocessing: The text data is tokenized, converted into sequences, and padded to ensure uniform input lengths. The sequences are then split into training and testing sets.\n","\n","3- Model Building: An LSTM model is constructed with an embedding layer, an LSTM layer, and a dense output layer with a softmax activation function to predict the probability of the next word.\n","\n","4- Model Training: The model is trained using the prepared sequences.\n","\n","5- Model Evaluation: The model is evaluated using a set of example sentences to test its ability to predict the next word accurately."]},{"cell_type":"markdown","metadata":{"id":"NxIreSfDAHWE"},"source":["## Import Libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T23:18:40.501613Z","iopub.status.busy":"2024-10-21T23:18:40.500610Z","iopub.status.idle":"2024-10-21T23:18:49.574763Z","shell.execute_reply":"2024-10-21T23:18:49.573838Z","shell.execute_reply.started":"2024-10-21T23:18:40.501568Z"},"id":"oRKWmEVO_-D-","trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import tensorflow\n","from tensorflow import keras"]},{"cell_type":"markdown","metadata":{"id":"XEQOekvsAKSm"},"source":["## Data Collection"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-10-21T23:18:49.577604Z","iopub.status.busy":"2024-10-21T23:18:49.576843Z","iopub.status.idle":"2024-10-21T23:18:51.492263Z","shell.execute_reply":"2024-10-21T23:18:51.491064Z","shell.execute_reply.started":"2024-10-21T23:18:49.577554Z"},"id":"Qc8fv5lqANW1","outputId":"0f9b2b31-544b-47cb-b8ad-ba9db04ada77","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package gutenberg to\n","[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Unzipping corpora\\gutenberg.zip.\n"]}],"source":["import nltk\n","nltk.download('gutenberg')\n","from nltk.corpus import gutenberg\n","\n","data=gutenberg.raw('shakespeare-hamlet.txt')\n","\n","# Save data as a file:\n","with open ('hamlet.txt','w') as file:\n","    file.write(data)"]},{"cell_type":"markdown","metadata":{"id":"rbk5na67BJMf"},"source":["## Data Preprocessing"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T23:18:51.494397Z","iopub.status.busy":"2024-10-21T23:18:51.493782Z","iopub.status.idle":"2024-10-21T23:18:51.519824Z","shell.execute_reply":"2024-10-21T23:18:51.518719Z","shell.execute_reply.started":"2024-10-21T23:18:51.494361Z"},"id":"57a8ksT3BMSY","trusted":true},"outputs":[],"source":["from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences"]},{"cell_type":"markdown","metadata":{"id":"dF4y4prkCHgm"},"source":["### Load Data"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T23:18:51.521289Z","iopub.status.busy":"2024-10-21T23:18:51.520990Z","iopub.status.idle":"2024-10-21T23:18:51.526930Z","shell.execute_reply":"2024-10-21T23:18:51.525864Z","shell.execute_reply.started":"2024-10-21T23:18:51.521256Z"},"id":"MB4vJ_xbCSNz","trusted":true},"outputs":[],"source":["with open ('hamlet.txt','r') as file:\n","    data=file.read().lower()"]},{"cell_type":"markdown","metadata":{"id":"xjyCfxbfGDdP"},"source":["### Tokenization"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-10-21T23:18:51.530143Z","iopub.status.busy":"2024-10-21T23:18:51.529800Z","iopub.status.idle":"2024-10-21T23:18:51.570931Z","shell.execute_reply":"2024-10-21T23:18:51.570057Z","shell.execute_reply.started":"2024-10-21T23:18:51.530109Z"},"id":"MZpXwd1_Csf2","outputId":"c53dafd2-a701-4f4d-bd5f-897709f56595","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Total Words: 4818\n"]}],"source":["tokenizer=Tokenizer()\n","tokenizer.fit_on_texts([data])\n","\n","# The tokenizer creates an internal word index (a dictionary) where each unique word is assigned an integer index.\n","# Words are assigned numbers based on the frequency (repeatability) with which they appear in the texts.\n","# Suppose, data = [\"a cat sat on the mat\", \"the cat is big\", \"a big cat\"]\n","# then, tokenizer.fit_on_texts([data]) gives output = {'cat': 1, 'a': 2, 'the': 3, 'big': 4, 'sat': 5, 'on': 6, 'mat': 7, 'is': 8}\n","# Here, \"cat\": appears 3 times, \"the\" & \"a\": appears 2 times and \"sat\", \"on\", \"mat\", \"is\", \"big\" each appear once.\n","\n","total_words=len(tokenizer.word_index)+1\n","print(f'Total Words: {total_words}') # Prints total number of unique words in data."]},{"cell_type":"markdown","metadata":{"id":"JC9QCWZiGTFT"},"source":["### Indices for each word in data"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ggMCcl1yFRsM","outputId":"218b6a4f-f895-4b33-9c62-b722fe251d4f","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[('the', 1), ('and', 2), ('to', 3), ('of', 4), ('i', 5), ('you', 6), ('a', 7), ('my', 8), ('it', 9), ('in', 10), ('that', 11), ('ham', 12), ('is', 13), ('not', 14), ('his', 15), ('this', 16), ('with', 17), ('your', 18), ('but', 19), ('for', 20)]\n"]}],"source":["# print(tokenizer.word_index)\n","print(list(tokenizer.word_index.items())[:20])"]},{"cell_type":"markdown","metadata":{"id":"xPMZ-LheGf0w"},"source":["### Create Input sequence of data"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-10-21T23:18:51.578976Z","iopub.status.busy":"2024-10-21T23:18:51.578617Z","iopub.status.idle":"2024-10-21T23:18:51.671650Z","shell.execute_reply":"2024-10-21T23:18:51.670602Z","shell.execute_reply.started":"2024-10-21T23:18:51.578944Z"},"id":"6NXA5OySFj4C","outputId":"f73eebad-2ac3-440d-94fe-3df0da70226e","trusted":true},"outputs":[{"data":{"text/plain":["[[1, 687],\n"," [1, 687, 4],\n"," [1, 687, 4, 45],\n"," [1, 687, 4, 45, 41],\n"," [1, 687, 4, 45, 41, 1886],\n"," [1, 687, 4, 45, 41, 1886, 1887],\n"," [1, 687, 4, 45, 41, 1886, 1887, 1888],\n"," [1180, 1889],\n"," [1180, 1889, 1890],\n"," [1180, 1889, 1890, 1891]]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["input_sequence = []\n","for line in data.split('\\n'):\n","    token_list = tokenizer.texts_to_sequences([line])[0]\n","    for i in range(1, len(token_list)):\n","        n_gram_sequence = token_list[:i+1]\n","        input_sequence.append(n_gram_sequence)\n","input_sequence[:10]"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":["25732"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["len(input_sequence)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":140},"execution":{"iopub.execute_input":"2024-10-21T23:18:51.673370Z","iopub.status.busy":"2024-10-21T23:18:51.673037Z","iopub.status.idle":"2024-10-21T23:18:51.680763Z","shell.execute_reply":"2024-10-21T23:18:51.679743Z","shell.execute_reply.started":"2024-10-21T23:18:51.673335Z"},"id":"kYkxHGwuYRGh","outputId":"dd0c360f-5fc5-4dd0-ea2b-8a16402369b6","trusted":true},"outputs":[{"data":{"text/plain":["'\\ntokenizer.texts_to_sequences([\"a cat sat on the mat\"])\\nThis will give output: [[2, 1, 5, 6, 3, 7]]\\nThis is beacuse: {\\'cat\\': 1, \\'a\\': 2, \\'the\\': 3, \\'big\\': 4, \\'sat\\': 5, \\'on\\': 6, \\'mat\\': 7, \\'is\\': 8}\\nThis is how we can create input sequnce of entire data line by line.\\n\\nExample: If a line in data is \"I love coding\", and the tokenizer converts it to [4, 7, 15], token_list will hold this list of word indices.\\n\\nfor i in range(1, len(token_list)):\\nThis loop runs from index 1 to the length of token_list. It starts at 1 because it is constructing sequences starting from the second word onwards.\\nFor example, if token_list is [4, 7, 15], i will take values from 1 to 2 (so it will construct n-grams of length 2 and 3).\\n\\nn_gram_sequence = token_list[:i+1]:\\nCreates an n-gram by taking a slice of token_list from the beginning up to the i+1-th element.\\nThis builds n-gram sequences incrementally, starting from a 2-gram and increasing with each iteration.\\n\\nExample:\\nIf token_list = [4, 7, 15], then:\\nWhen i = 1: n_gram_sequence = [4, 7]\\nWhen i = 2: n_gram_sequence = [4, 7, 15] & so on...\\n'"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["'''\n","tokenizer.texts_to_sequences([\"a cat sat on the mat\"])\n","This will give output: [[2, 1, 5, 6, 3, 7]]\n","This is beacuse: {'cat': 1, 'a': 2, 'the': 3, 'big': 4, 'sat': 5, 'on': 6, 'mat': 7, 'is': 8}\n","This is how we can create input sequnce of entire data line by line.\n","\n","Example: If a line in data is \"I love coding\", and the tokenizer converts it to [4, 7, 15], token_list will hold this list of word indices.\n","\n","for i in range(1, len(token_list)):\n","This loop runs from index 1 to the length of token_list. It starts at 1 because it is constructing sequences starting from the second word onwards.\n","For example, if token_list is [4, 7, 15], i will take values from 1 to 2 (so it will construct n-grams of length 2 and 3).\n","\n","n_gram_sequence = token_list[:i+1]:\n","Creates an n-gram by taking a slice of token_list from the beginning up to the i+1-th element.\n","This builds n-gram sequences incrementally, starting from a 2-gram and increasing with each iteration.\n","\n","Example:\n","If token_list = [4, 7, 15], then:\n","When i = 1: n_gram_sequence = [4, 7]\n","When i = 2: n_gram_sequence = [4, 7, 15] & so on...\n","'''"]},{"cell_type":"markdown","metadata":{"id":"D-KNqFDOYGXU"},"source":["### Create Padding for fixed input size"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-10-21T23:18:51.682388Z","iopub.status.busy":"2024-10-21T23:18:51.682082Z","iopub.status.idle":"2024-10-21T23:18:51.697669Z","shell.execute_reply":"2024-10-21T23:18:51.696891Z","shell.execute_reply.started":"2024-10-21T23:18:51.682355Z"},"id":"IZj1rZcCYFwM","outputId":"46413ccd-bc54-4559-e163-b259ad163f92","trusted":true},"outputs":[{"data":{"text/plain":["14"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["max_length=max([len(x) for x in input_sequence])\n","max_length\n"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-10-21T23:18:51.710833Z","iopub.status.busy":"2024-10-21T23:18:51.710489Z","iopub.status.idle":"2024-10-21T23:18:51.819441Z","shell.execute_reply":"2024-10-21T23:18:51.818523Z","shell.execute_reply.started":"2024-10-21T23:18:51.710800Z"},"id":"YDhcuLJDZS0O","outputId":"0ea0074c-7861-4e9b-a952-7367e5e22a15","trusted":true},"outputs":[{"data":{"text/plain":["array([[   0,    0,    0, ...,    0,    1,  687],\n","       [   0,    0,    0, ...,    1,  687,    4],\n","       [   0,    0,    0, ...,  687,    4,   45],\n","       ...,\n","       [   0,    0,    0, ...,    4,   45, 1047],\n","       [   0,    0,    0, ...,   45, 1047,    4],\n","       [   0,    0,    0, ..., 1047,    4,  193]])"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["input_sequences=np.array(pad_sequences(input_sequence,maxlen=max_length,padding='pre'))\n","input_sequences"]},{"cell_type":"markdown","metadata":{"id":"YddPPm0uZhBh"},"source":["## Define X and y"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-10-21T23:18:51.820830Z","iopub.status.busy":"2024-10-21T23:18:51.820563Z","iopub.status.idle":"2024-10-21T23:18:51.829061Z","shell.execute_reply":"2024-10-21T23:18:51.828003Z","shell.execute_reply.started":"2024-10-21T23:18:51.820802Z"},"id":"q9OzjUEjaCww","outputId":"1cb9403a-d587-48f7-e2e7-2af965d5f700","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(25732, 13)\n","(25732,)\n"]},{"data":{"text/plain":["array([[   0,    0,    0, ...,    0,    0,    1],\n","       [   0,    0,    0, ...,    0,    1,  687],\n","       [   0,    0,    0, ...,    1,  687,    4],\n","       ...,\n","       [   0,    0,    0, ...,  687,    4,   45],\n","       [   0,    0,    0, ...,    4,   45, 1047],\n","       [   0,    0,    0, ...,   45, 1047,    4]])"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["X,y=input_sequences[:,:-1],input_sequences[:,-1]\n","print(X.shape),print(y.shape)\n","X"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-10-21T23:18:51.830753Z","iopub.status.busy":"2024-10-21T23:18:51.830375Z","iopub.status.idle":"2024-10-21T23:18:51.841144Z","shell.execute_reply":"2024-10-21T23:18:51.840049Z","shell.execute_reply.started":"2024-10-21T23:18:51.830711Z"},"id":"nuQeQf49aRXg","outputId":"5982cdbb-8d3e-47b1-de69-d326a531701f","trusted":true},"outputs":[{"data":{"text/plain":["array([ 687,    4,   45, ..., 1047,    4,  193])"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["y"]},{"cell_type":"markdown","metadata":{"id":"XRV3SlrzaTzc"},"source":["### Convert y into categorical feature for next word prediction"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-10-21T23:18:51.846514Z","iopub.status.busy":"2024-10-21T23:18:51.846177Z","iopub.status.idle":"2024-10-21T23:18:51.920545Z","shell.execute_reply":"2024-10-21T23:18:51.919355Z","shell.execute_reply.started":"2024-10-21T23:18:51.846459Z"},"id":"d-uB7X_LaSgm","outputId":"a8e03f54-5c08-448c-e73d-04523d61abfa","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(25732, 4818)\n"]},{"data":{"text/plain":["array([[0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       ...,\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.]])"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["y=keras.utils.to_categorical(y,num_classes=total_words)\n","print(y.shape)\n","y"]},{"cell_type":"markdown","metadata":{"id":"pVp3rI-Tami5"},"source":["## Train-Test Split"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-10-21T23:18:51.922394Z","iopub.status.busy":"2024-10-21T23:18:51.922091Z","iopub.status.idle":"2024-10-21T23:18:52.509138Z","shell.execute_reply":"2024-10-21T23:18:52.508143Z","shell.execute_reply.started":"2024-10-21T23:18:51.922363Z"},"id":"hWZC_rdFaqMd","outputId":"a5a98ebe-fb24-4aeb-86b2-1e067c9e2e7b","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(20585, 13)\n","(5147, 13)\n","(20585, 4818)\n","(5147, 4818)\n"]}],"source":["from sklearn.model_selection import train_test_split\n","X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n","print(X_train.shape)\n","print(X_test.shape)\n","print(y_train.shape)\n","print(y_test.shape)"]},{"cell_type":"markdown","metadata":{"id":"L7rvICcHbP2x"},"source":["## LSTM Model"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T23:18:52.510711Z","iopub.status.busy":"2024-10-21T23:18:52.510357Z","iopub.status.idle":"2024-10-21T23:18:52.518248Z","shell.execute_reply":"2024-10-21T23:18:52.517272Z","shell.execute_reply.started":"2024-10-21T23:18:52.510677Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'\\nfrom tensorflow.keras.layers import Embedding,LSTM,Dense,Dropout\\nfrom tensorflow.keras.models import Sequential\\n\\ndef create_model(lstm_units=64, lstm_units2=128, embedding_dim=50, optimizer=\\'adam\\'):\\n    model = Sequential()\\n    model.add(Embedding(total_words, embedding_dim, input_shape=(max_length-1,)))\\n    \\n    model.add(LSTM(lstm_units, return_sequences=True))\\n    \\n    model.add(Dropout(0.3))  # Dropout can be made tunable\\n\\n    model.add(LSTM(lstm_units2))  # Final LSTM layer\\n    \\n    model.add(Dense(total_words, activation=\\'softmax\\'))\\n    \\n    # Compile with passed optimizer\\n    model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\\'accuracy\\'])\\n    \\n    # Print model summary\\n    print(\"Model Summary:\")\\n    model.summary()\\n\\n    # Explicitly set the compiled attribute for compatibility with SciKeras\\n    model.compiled = True\\n\\n    return model\\n\\n# No optimizer tuning for now\\nfrom scikeras.wrappers import KerasClassifier\\nmodel = KerasClassifier(model=create_model, verbose=1, lstm_units=128, lstm_units2=64, embedding_dim=50)\\n\\nparam_grid = {\\n    \\'lstm_units\\': [128, 256],\\n    \\'lstm_units2\\': [64, 128],\\n    \\'embedding_dim\\': [50, 100],\\n    \\'epochs\\': [100]\\n}\\n\\nfrom sklearn.model_selection import GridSearchCV\\ngrid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, verbose=2)\\ngrid_result = grid.fit(X, y, batch_size=16)\\n\\n# Output best result\\nprint(f\"Best score: {grid_result.best_score_} using {grid_result.best_params_}\")\\n'"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["'''\n","from tensorflow.keras.layers import Embedding,LSTM,Dense,Dropout\n","from tensorflow.keras.models import Sequential\n","\n","def create_model(lstm_units=64, lstm_units2=128, embedding_dim=50, optimizer='adam'):\n","    model = Sequential()\n","    model.add(Embedding(total_words, embedding_dim, input_shape=(max_length-1,)))\n","    \n","    model.add(LSTM(lstm_units, return_sequences=True))\n","    \n","    model.add(Dropout(0.3))  # Dropout can be made tunable\n","\n","    model.add(LSTM(lstm_units2))  # Final LSTM layer\n","    \n","    model.add(Dense(total_words, activation='softmax'))\n","    \n","    # Compile with passed optimizer\n","    model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=['accuracy'])\n","    \n","    # Print model summary\n","    print(\"Model Summary:\")\n","    model.summary()\n","\n","    # Explicitly set the compiled attribute for compatibility with SciKeras\n","    model.compiled = True\n","\n","    return model\n","\n","# No optimizer tuning for now\n","from scikeras.wrappers import KerasClassifier\n","model = KerasClassifier(model=create_model, verbose=1, lstm_units=128, lstm_units2=64, embedding_dim=50)\n","\n","param_grid = {\n","    'lstm_units': [128, 256],\n","    'lstm_units2': [64, 128],\n","    'embedding_dim': [50, 100],\n","    'epochs': [100]\n","}\n","\n","from sklearn.model_selection import GridSearchCV\n","grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, verbose=2)\n","grid_result = grid.fit(X, y, batch_size=16)\n","\n","# Output best result\n","print(f\"Best score: {grid_result.best_score_} using {grid_result.best_params_}\")\n","'''"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T23:18:52.519572Z","iopub.status.busy":"2024-10-21T23:18:52.519256Z","iopub.status.idle":"2024-10-21T23:18:53.803825Z","shell.execute_reply":"2024-10-21T23:18:53.802919Z","shell.execute_reply.started":"2024-10-21T23:18:52.519540Z"},"id":"5YF_9Gc7aiHM","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["f:\\Generative AI\\GenAI\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"sequential\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">240,900</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">91,648</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4818</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">621,522</span> │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │       \u001b[38;5;34m240,900\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m91,648\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4818\u001b[0m)           │       \u001b[38;5;34m621,522\u001b[0m │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">954,070</span> (3.64 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m954,070\u001b[0m (3.64 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">954,070</span> (3.64 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m954,070\u001b[0m (3.64 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"}],"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding,LSTM,Dense\n","\n","# Define Model\n","model=Sequential()\n","model.add(Embedding(total_words, 50, input_shape=(max_length-1,)))\n","model.add(LSTM(128))\n","model.add(Dense(total_words,activation='softmax'))\n","\n","#Compile Model\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","model.summary()\n"]},{"cell_type":"markdown","metadata":{"id":"8-7ZQb0Wd0Vr"},"source":["## Train Model"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T23:18:53.806073Z","iopub.status.busy":"2024-10-21T23:18:53.805196Z"},"id":"W0u35Nadb5b5","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 28ms/step - accuracy: 0.0289 - loss: 7.1340 - val_accuracy: 0.0404 - val_loss: 6.7031\n","Epoch 2/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 25ms/step - accuracy: 0.0415 - loss: 6.4706 - val_accuracy: 0.0412 - val_loss: 6.7605\n","Epoch 3/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 27ms/step - accuracy: 0.0439 - loss: 6.3172 - val_accuracy: 0.0490 - val_loss: 6.7819\n","Epoch 4/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 37ms/step - accuracy: 0.0550 - loss: 6.0775 - val_accuracy: 0.0513 - val_loss: 6.8025\n","Epoch 5/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 26ms/step - accuracy: 0.0611 - loss: 5.9063 - val_accuracy: 0.0622 - val_loss: 6.8439\n","Epoch 6/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 25ms/step - accuracy: 0.0697 - loss: 5.7198 - val_accuracy: 0.0674 - val_loss: 6.9117\n","Epoch 7/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 25ms/step - accuracy: 0.0832 - loss: 5.5038 - val_accuracy: 0.0678 - val_loss: 6.9935\n","Epoch 8/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 26ms/step - accuracy: 0.0944 - loss: 5.2653 - val_accuracy: 0.0696 - val_loss: 7.0851\n","Epoch 9/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 25ms/step - accuracy: 0.1038 - loss: 5.0746 - val_accuracy: 0.0725 - val_loss: 7.1622\n","Epoch 10/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 26ms/step - accuracy: 0.1169 - loss: 4.8391 - val_accuracy: 0.0694 - val_loss: 7.2778\n","Epoch 11/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 26ms/step - accuracy: 0.1305 - loss: 4.6671 - val_accuracy: 0.0731 - val_loss: 7.3803\n","Epoch 12/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 26ms/step - accuracy: 0.1533 - loss: 4.4448 - val_accuracy: 0.0678 - val_loss: 7.4972\n","Epoch 13/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 27ms/step - accuracy: 0.1762 - loss: 4.2636 - val_accuracy: 0.0690 - val_loss: 7.6079\n","Epoch 14/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 27ms/step - accuracy: 0.2115 - loss: 4.0487 - val_accuracy: 0.0715 - val_loss: 7.7306\n","Epoch 15/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 27ms/step - accuracy: 0.2362 - loss: 3.8673 - val_accuracy: 0.0709 - val_loss: 7.8392\n","Epoch 16/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 26ms/step - accuracy: 0.2739 - loss: 3.6809 - val_accuracy: 0.0705 - val_loss: 7.9606\n","Epoch 17/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 26ms/step - accuracy: 0.3061 - loss: 3.5102 - val_accuracy: 0.0661 - val_loss: 8.0871\n","Epoch 18/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 27ms/step - accuracy: 0.3286 - loss: 3.3656 - val_accuracy: 0.0645 - val_loss: 8.2202\n","Epoch 19/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 26ms/step - accuracy: 0.3595 - loss: 3.2028 - val_accuracy: 0.0622 - val_loss: 8.3215\n","Epoch 20/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 26ms/step - accuracy: 0.3936 - loss: 3.0187 - val_accuracy: 0.0626 - val_loss: 8.4377\n","Epoch 21/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 27ms/step - accuracy: 0.4062 - loss: 2.9188 - val_accuracy: 0.0614 - val_loss: 8.5733\n","Epoch 22/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 27ms/step - accuracy: 0.4396 - loss: 2.7734 - val_accuracy: 0.0612 - val_loss: 8.7009\n","Epoch 23/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 27ms/step - accuracy: 0.4593 - loss: 2.6496 - val_accuracy: 0.0569 - val_loss: 8.7915\n","Epoch 24/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 27ms/step - accuracy: 0.4882 - loss: 2.5128 - val_accuracy: 0.0563 - val_loss: 8.9181\n","Epoch 25/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 27ms/step - accuracy: 0.5049 - loss: 2.4234 - val_accuracy: 0.0556 - val_loss: 9.0185\n","Epoch 26/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 27ms/step - accuracy: 0.5187 - loss: 2.3364 - val_accuracy: 0.0558 - val_loss: 9.1304\n","Epoch 27/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 27ms/step - accuracy: 0.5432 - loss: 2.2355 - val_accuracy: 0.0579 - val_loss: 9.2440\n","Epoch 28/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 27ms/step - accuracy: 0.5633 - loss: 2.1447 - val_accuracy: 0.0558 - val_loss: 9.3588\n","Epoch 29/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 27ms/step - accuracy: 0.5808 - loss: 2.0550 - val_accuracy: 0.0546 - val_loss: 9.4595\n","Epoch 30/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 27ms/step - accuracy: 0.5938 - loss: 1.9771 - val_accuracy: 0.0587 - val_loss: 9.5506\n","Epoch 31/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 27ms/step - accuracy: 0.6149 - loss: 1.8907 - val_accuracy: 0.0556 - val_loss: 9.6432\n","Epoch 32/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step - accuracy: 0.6292 - loss: 1.8262 - val_accuracy: 0.0528 - val_loss: 9.7626\n","Epoch 33/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 28ms/step - accuracy: 0.6440 - loss: 1.7479 - val_accuracy: 0.0565 - val_loss: 9.8477\n","Epoch 34/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 29ms/step - accuracy: 0.6677 - loss: 1.6429 - val_accuracy: 0.0563 - val_loss: 9.9605\n","Epoch 35/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 28ms/step - accuracy: 0.6735 - loss: 1.6083 - val_accuracy: 0.0554 - val_loss: 10.0530\n","Epoch 36/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 28ms/step - accuracy: 0.6816 - loss: 1.5550 - val_accuracy: 0.0552 - val_loss: 10.1348\n","Epoch 37/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 27ms/step - accuracy: 0.6979 - loss: 1.4847 - val_accuracy: 0.0560 - val_loss: 10.2487\n","Epoch 38/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 28ms/step - accuracy: 0.7080 - loss: 1.4405 - val_accuracy: 0.0552 - val_loss: 10.3357\n","Epoch 39/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 28ms/step - accuracy: 0.7196 - loss: 1.3750 - val_accuracy: 0.0538 - val_loss: 10.4378\n","Epoch 40/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 28ms/step - accuracy: 0.7288 - loss: 1.3347 - val_accuracy: 0.0544 - val_loss: 10.5341\n","Epoch 41/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 28ms/step - accuracy: 0.7405 - loss: 1.2721 - val_accuracy: 0.0534 - val_loss: 10.6254\n","Epoch 42/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step - accuracy: 0.7474 - loss: 1.2429 - val_accuracy: 0.0556 - val_loss: 10.7229\n","Epoch 43/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step - accuracy: 0.7516 - loss: 1.1988 - val_accuracy: 0.0534 - val_loss: 10.7957\n","Epoch 44/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 28ms/step - accuracy: 0.7565 - loss: 1.1784 - val_accuracy: 0.0528 - val_loss: 10.9161\n","Epoch 45/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step - accuracy: 0.7696 - loss: 1.1303 - val_accuracy: 0.0499 - val_loss: 10.9986\n","Epoch 46/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 28ms/step - accuracy: 0.7732 - loss: 1.0917 - val_accuracy: 0.0521 - val_loss: 11.0789\n","Epoch 47/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step - accuracy: 0.7755 - loss: 1.0761 - val_accuracy: 0.0515 - val_loss: 11.1586\n","Epoch 48/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 28ms/step - accuracy: 0.7866 - loss: 1.0286 - val_accuracy: 0.0525 - val_loss: 11.2451\n","Epoch 49/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step - accuracy: 0.7975 - loss: 0.9778 - val_accuracy: 0.0503 - val_loss: 11.3343\n","Epoch 50/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 28ms/step - accuracy: 0.7931 - loss: 0.9818 - val_accuracy: 0.0492 - val_loss: 11.4132\n","Epoch 51/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 29ms/step - accuracy: 0.8009 - loss: 0.9489 - val_accuracy: 0.0499 - val_loss: 11.5068\n","Epoch 52/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 29ms/step - accuracy: 0.8016 - loss: 0.9413 - val_accuracy: 0.0503 - val_loss: 11.5980\n","Epoch 53/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 29ms/step - accuracy: 0.8045 - loss: 0.9221 - val_accuracy: 0.0488 - val_loss: 11.6533\n","Epoch 54/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 29ms/step - accuracy: 0.8107 - loss: 0.8848 - val_accuracy: 0.0484 - val_loss: 11.7420\n","Epoch 55/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 29ms/step - accuracy: 0.8101 - loss: 0.8706 - val_accuracy: 0.0476 - val_loss: 11.8262\n","Epoch 56/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 30ms/step - accuracy: 0.8107 - loss: 0.8651 - val_accuracy: 0.0503 - val_loss: 11.9202\n","Epoch 57/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 29ms/step - accuracy: 0.8210 - loss: 0.8186 - val_accuracy: 0.0497 - val_loss: 11.9994\n","Epoch 58/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 30ms/step - accuracy: 0.8270 - loss: 0.8012 - val_accuracy: 0.0455 - val_loss: 12.0795\n","Epoch 59/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 29ms/step - accuracy: 0.8196 - loss: 0.8118 - val_accuracy: 0.0476 - val_loss: 12.1178\n","Epoch 60/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 30ms/step - accuracy: 0.8280 - loss: 0.7765 - val_accuracy: 0.0501 - val_loss: 12.2096\n","Epoch 61/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 29ms/step - accuracy: 0.8253 - loss: 0.7775 - val_accuracy: 0.0495 - val_loss: 12.3062\n","Epoch 62/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 29ms/step - accuracy: 0.8266 - loss: 0.7607 - val_accuracy: 0.0466 - val_loss: 12.3389\n","Epoch 63/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 30ms/step - accuracy: 0.8311 - loss: 0.7331 - val_accuracy: 0.0459 - val_loss: 12.4266\n","Epoch 64/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 32ms/step - accuracy: 0.8355 - loss: 0.7240 - val_accuracy: 0.0492 - val_loss: 12.4871\n","Epoch 65/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 31ms/step - accuracy: 0.8324 - loss: 0.7268 - val_accuracy: 0.0488 - val_loss: 12.5958\n","Epoch 66/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 30ms/step - accuracy: 0.8336 - loss: 0.7148 - val_accuracy: 0.0466 - val_loss: 12.6360\n","Epoch 67/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 31ms/step - accuracy: 0.8335 - loss: 0.6986 - val_accuracy: 0.0482 - val_loss: 12.7085\n","Epoch 68/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 31ms/step - accuracy: 0.8402 - loss: 0.6708 - val_accuracy: 0.0472 - val_loss: 12.7581\n","Epoch 69/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 31ms/step - accuracy: 0.8371 - loss: 0.6746 - val_accuracy: 0.0466 - val_loss: 12.8556\n","Epoch 70/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 31ms/step - accuracy: 0.8388 - loss: 0.6742 - val_accuracy: 0.0451 - val_loss: 12.9231\n","Epoch 71/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 32ms/step - accuracy: 0.8429 - loss: 0.6572 - val_accuracy: 0.0447 - val_loss: 12.9965\n","Epoch 72/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 33ms/step - accuracy: 0.8423 - loss: 0.6514 - val_accuracy: 0.0462 - val_loss: 13.0425\n","Epoch 73/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 36ms/step - accuracy: 0.8422 - loss: 0.6453 - val_accuracy: 0.0464 - val_loss: 13.0906\n","Epoch 74/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 33ms/step - accuracy: 0.8436 - loss: 0.6355 - val_accuracy: 0.0439 - val_loss: 13.1652\n","Epoch 75/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - accuracy: 0.8444 - loss: 0.6308 - val_accuracy: 0.0447 - val_loss: 13.2094\n","Epoch 76/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 33ms/step - accuracy: 0.8468 - loss: 0.6199 - val_accuracy: 0.0476 - val_loss: 13.2975\n","Epoch 77/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 34ms/step - accuracy: 0.8406 - loss: 0.6407 - val_accuracy: 0.0457 - val_loss: 13.3200\n","Epoch 78/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 34ms/step - accuracy: 0.8418 - loss: 0.6240 - val_accuracy: 0.0459 - val_loss: 13.3860\n","Epoch 79/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 32ms/step - accuracy: 0.8450 - loss: 0.6098 - val_accuracy: 0.0474 - val_loss: 13.4437\n","Epoch 80/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 32ms/step - accuracy: 0.8479 - loss: 0.5925 - val_accuracy: 0.0462 - val_loss: 13.5175\n","Epoch 81/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 33ms/step - accuracy: 0.8455 - loss: 0.5941 - val_accuracy: 0.0462 - val_loss: 13.5599\n","Epoch 82/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 33ms/step - accuracy: 0.8523 - loss: 0.5815 - val_accuracy: 0.0441 - val_loss: 13.6230\n","Epoch 83/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 32ms/step - accuracy: 0.8470 - loss: 0.5966 - val_accuracy: 0.0466 - val_loss: 13.6581\n","Epoch 84/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 34ms/step - accuracy: 0.8475 - loss: 0.5818 - val_accuracy: 0.0476 - val_loss: 13.7143\n","Epoch 85/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 33ms/step - accuracy: 0.8457 - loss: 0.6019 - val_accuracy: 0.0459 - val_loss: 13.7681\n","Epoch 86/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 33ms/step - accuracy: 0.8498 - loss: 0.5632 - val_accuracy: 0.0457 - val_loss: 13.8260\n","Epoch 87/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 33ms/step - accuracy: 0.8529 - loss: 0.5545 - val_accuracy: 0.0439 - val_loss: 13.8784\n","Epoch 88/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 37ms/step - accuracy: 0.8458 - loss: 0.5714 - val_accuracy: 0.0435 - val_loss: 13.8887\n","Epoch 89/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 37ms/step - accuracy: 0.8467 - loss: 0.5745 - val_accuracy: 0.0429 - val_loss: 13.9911\n","Epoch 90/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 35ms/step - accuracy: 0.8451 - loss: 0.5832 - val_accuracy: 0.0459 - val_loss: 14.0392\n","Epoch 91/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 36ms/step - accuracy: 0.8518 - loss: 0.5442 - val_accuracy: 0.0464 - val_loss: 14.0591\n","Epoch 92/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 34ms/step - accuracy: 0.8474 - loss: 0.5632 - val_accuracy: 0.0460 - val_loss: 14.1146\n","Epoch 93/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 34ms/step - accuracy: 0.8459 - loss: 0.5731 - val_accuracy: 0.0425 - val_loss: 14.1317\n","Epoch 94/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 34ms/step - accuracy: 0.8475 - loss: 0.5610 - val_accuracy: 0.0435 - val_loss: 14.1821\n","Epoch 95/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 36ms/step - accuracy: 0.8470 - loss: 0.5567 - val_accuracy: 0.0443 - val_loss: 14.2178\n","Epoch 96/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 34ms/step - accuracy: 0.8445 - loss: 0.5681 - val_accuracy: 0.0439 - val_loss: 14.2516\n","Epoch 97/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 34ms/step - accuracy: 0.8515 - loss: 0.5504 - val_accuracy: 0.0441 - val_loss: 14.2647\n","Epoch 98/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 35ms/step - accuracy: 0.8520 - loss: 0.5341 - val_accuracy: 0.0457 - val_loss: 14.3439\n","Epoch 99/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 36ms/step - accuracy: 0.8485 - loss: 0.5438 - val_accuracy: 0.0437 - val_loss: 14.3773\n","Epoch 100/100\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 35ms/step - accuracy: 0.8499 - loss: 0.5401 - val_accuracy: 0.0451 - val_loss: 14.4328\n"]}],"source":["history=model.fit(X_train,y_train, validation_data=(X_test,y_test), epochs=100,verbose=1)"]},{"cell_type":"markdown","metadata":{"id":"ivVmxtoo2h3u"},"source":["## Save model and Tokenizer"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"xguouQVk2g05","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]}],"source":["model.save('model.h5')\n","\n","import pickle\n","with open('tokenizer.pickle','wb') as handle:\n","    pickle.dump(tokenizer,handle,protocol=pickle.HIGHEST_PROTOCOL)"]},{"cell_type":"markdown","metadata":{"id":"HYQ4Vmv32rrs"},"source":["## Prediction"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"aIBKRl4z2vaw","trusted":true},"outputs":[],"source":["def predict_next_word(model,tokenizer,data,max_length):\n","    token_list = tokenizer.texts_to_sequences([data])[0]\n","    if len(token_list) >= max_length:\n","        token_list = token_list[-(max_length-1):] # Ensure the sequnce length matches the max length\n","    token_list = pad_sequences([token_list], maxlen=max_length-1, padding='pre')\n","    prediction = model.predict(token_list, verbose=0)\n","    predicted_index = np.argmax(prediction, axis=1)\n","    for word,index in tokenizer.word_index.items():\n","        if index == predicted_index:\n","            return word\n","    return None"]},{"cell_type":"markdown","metadata":{"id":"z5-oDHoI5Pra"},"source":["### Sample Prediction"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"NdTgww1p5ULh","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Sample Text: The Tragedie of Hamlet by William\n","Next Word: shakespeare\n"]}],"source":["sample=\"The Tragedie of Hamlet by William\"\n","print(f'Sample Text: {sample}')\n","max_length=model.input_shape[1]+1\n","next_word=predict_next_word(model,tokenizer,sample,max_length)\n","print(f'Next Word: {next_word}')"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30787,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"GenAI","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":4}
